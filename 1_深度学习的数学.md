神经网络的思想(深度学习的数学)


深度学习是人工智能具有代表性的实现方法。
人脑几千亿神经元，每个都有作用。

神经元
- [x] 1.神经元形成网络
- [x] 2.对于其他多个神经元传递过来的信号，如果不超过某个阀值，神经元不做任何反应
- [x] 3.如果传递过来的信号，超过某个阀值，神经元做出反应(称为点火)，向另外的神经元传递固定强度的信号
- [x] 4.从多个神经元传递过来的信号中，每个信号对应的权重不一样。

将神经元的工作在数学上抽象化，并以其为单位人工的形成网络，这样的人工网络就是神经网络。神经网络是以神经元抽象出来的数学模型为出发点。

对于神经网络实现的人工智能，人只需要提供数据即可，神经网络接收数据后，会从网络的关系中自己学习并理解。

对于生命来说，神经元忽略微小的输入信号，十分重要。
神经元对任何微小的信号都变得兴奋，神经系统就将”情绪不稳定”。

数学表示：
输入信号X1，X2，对应权重W1,W2。
- [x] 无信号输出 X1W1+X2W2 < 0;
- [x] 有信号输出 X1W1+X2W2 >= 0;

例子：
假如权重W1=5,W2=3,阀值=4
输入X1	输入X2	X1W1+X2W2 	点火	输出信号y
0	0	5*0+3*0=0<4	无	0
0	1	5*0+3*1=3<4	无	0
1	0	5*0+3*1=5>4	有	1
1	1	5*0+3*1=8>4	有	1

如果用函数式表示，需要用到单位阶跃函数。
z=X1W1+X2W2 - 阀值。 称为神经元的加权输入

激活函数：
根据是否点火，输出y分别取值0和1；
y=a（X1W1+X2W2 - 阀值），这里的函数a就是建模者定义的函数，称为激活函数；这个函数就是神经网络的出发点。

神经元(生物学上的称呼)，简化和抽象化的神经元称为神经单元。神经单元就是神经元的模型化。
￼

偏置
y=a（X1W1+X2W2 - 阀值），如果阀值较大，表示神经元不容易兴奋。数学不喜欢不漂亮的东西，- 阀值替换为+b，这个b称为偏置
* y=a（X1W1+X2W2 +b）；
* 此时的恶加权输入z=X1W1+X2W2 +b；

z=X1W1+X2W2 +b*1，加权输入z可以看到两个向量的内积
(W1,w2,w3,b)(x1,x2,x3,1),计算机擅长内积的计算。


阶层型神经网络

￼![阶层型神经网络的示例。](https://github.com/user-attachments/assets/c67ce46b-3331-4b7a-8346-3e34ed4a1389)


深度学习，顾名思义，是叠加了很多层的神经网络。叠加层有各种各样的方法，其中著名的是卷积神经网络。

隐藏层肩负着提取特征的职责。

请想象一下生物看东西时的情形。可以认为，输入层神经单元相当于视细胞，隐藏层神经单元相当于视神经细胞，输出层神经单元相当于负责判断的大脑神经细胞群。

￼![Pasted Graphic 2](https://github.com/user-attachments/assets/8996ca3d-91e9-4c15-a818-5443a52cfc3a)


神经网络中比较重要的一点就是利用网络自学习算法来确定权重大小。

神经网络学习

神经网络的参数确定方法分为有监督学习和无监督学习。有监督学习是指，为了确定神经网络的权重和偏置，事先给予数据，这些数据称为学习数据。根据给定的学习数据确定权重和偏置，称为学习。思路极其简单：计算神经网络得出的预测值与正解的误差，确定使得误差总和达到最小的权重和偏置。这在数学上称为模型的最优化（下图）。
￼
![最优化是指确定使得误差总和最小的参数的方法。](https://github.com/user-attachments/assets/5ce183ae-7648-4e8e-b22b-a3746ccea754)


利用平方误差确定参数的方法在数学上称为最小二乘法，它在统计学中是回归分析的常规手段。
